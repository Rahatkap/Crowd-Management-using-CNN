{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5v-KMx2KHKmL"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Set the path for the input image\n",
        "img_name = 'image.jpg'\n",
        "img = cv2.imread(img_name)\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "# Load YOLO model weights and configuration\n",
        "net = cv2.dnn.readNetFromDarknet('yolov3-custom.cfg', 'yolov3-custom.weights')\n",
        "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
        "\n",
        "# Load the classes from the dataset (make sure 'person' is correctly labeled in your 'crowd.names')\n",
        "classes = open('crowd.names').read().strip().split('\\n')\n",
        "colors = np.random.randint(0, 255, size=(len(classes), 3), dtype='uint8')\n",
        "\n",
        "# Determine only the output layer names that we need from YOLO\n",
        "ln = [net.getLayerNames()[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "# Convert image to blob\n",
        "blob = cv2.dnn.blobFromImage(img, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
        "net.setInput(blob)\n",
        "outputs = net.forward(ln)\n",
        "\n",
        "boxes = []\n",
        "confidences = []\n",
        "classIDs = []\n",
        "h, w = img.shape[:2]\n",
        "\n",
        "# Initialize counter for people\n",
        "people_count = 0\n",
        "\n",
        "# Process each of the outputs from the network\n",
        "for output in outputs:\n",
        "    for detection in output:\n",
        "        scores = detection[5:]\n",
        "        classID = np.argmax(scores)\n",
        "        confidence = scores[classID]\n",
        "        if confidence > 0.5:\n",
        "            box = detection[:4] * np.array([w, h, w, h])\n",
        "            (centerX, centerY, width, height) = box.astype(\"int\")\n",
        "            x = int(centerX - (width / 2))\n",
        "            y = int(centerY - (height / 2))\n",
        "            boxes.append([x, y, int(width), int(height)])\n",
        "            confidences.append(float(confidence))\n",
        "            classIDs.append(classID)\n",
        "\n",
        "            # Count if the detected class is 'person'\n",
        "            if classes[classID] == 'person':\n",
        "                people_count += 1\n",
        "\n",
        "# Perform non maximum suppression to eliminate redundant overlapping boxes with lower confidences\n",
        "indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "if len(indices) > 0:\n",
        "    for i in indices.flatten():\n",
        "        (x, y, w, h) = boxes[i]\n",
        "        color = [int(c) for c in colors[classIDs[i]]]\n",
        "        cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
        "        text = \"{}: {:.4f}\".format(classes[classIDs[i]], confidences[i])\n",
        "        cv2.putText(img, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "# Output the result\n",
        "print(f\"Number of people detected: {people_count}\")\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.title('Detected Objects')\n",
        "plt.show()\n"
      ]
    }
  ]
}